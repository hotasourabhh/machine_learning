{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives : \n",
    "\n",
    "-  Use scikit learn to classify\n",
    "-  Understand confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset\n",
    "\n",
    "We will use a telecommunications dataset for predicting customer churn. This is a historical customer dataset where each row represents one customer. The data is relatively easy to understand, and you may uncover insights you can use immediately. Typically it is less expensive to keep customers than acquire new ones, so the focus of this analysis is to predict the customers who will stay with the company.\n",
    "This data set provides information to help you predict what behavior will help you to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\n",
    "\n",
    "The dataset includes information about:\n",
    "\n",
    "Customers who left within the last month – the column is called Churn\n",
    "Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
    "Customer account information – how long they had been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n",
    "Demographic info about customers – gender, age range, and if they have partners and dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>longmon</th>\n",
       "      <th>...</th>\n",
       "      <th>pager</th>\n",
       "      <th>internet</th>\n",
       "      <th>callwait</th>\n",
       "      <th>confer</th>\n",
       "      <th>ebill</th>\n",
       "      <th>loglong</th>\n",
       "      <th>logtoll</th>\n",
       "      <th>lninc</th>\n",
       "      <th>custcat</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.482</td>\n",
       "      <td>3.033</td>\n",
       "      <td>4.913</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.246</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.841</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.401</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.800</td>\n",
       "      <td>3.807</td>\n",
       "      <td>4.331</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.960</td>\n",
       "      <td>3.091</td>\n",
       "      <td>4.382</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.030</td>\n",
       "      <td>3.240</td>\n",
       "      <td>4.787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.110</td>\n",
       "      <td>3.157</td>\n",
       "      <td>3.611</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.065</td>\n",
       "      <td>3.240</td>\n",
       "      <td>2.833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.872</td>\n",
       "      <td>3.314</td>\n",
       "      <td>4.942</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.553</td>\n",
       "      <td>3.248</td>\n",
       "      <td>4.143</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
       "0    11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
       "1    33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
       "2    23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
       "3    38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
       "4     7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
       "5    68.0  52.0     17.0   120.0  1.0    24.0    0.0       1.0       0.0   \n",
       "6    42.0  40.0      7.0    37.0  2.0     8.0    1.0       1.0       1.0   \n",
       "7     9.0  21.0      1.0    17.0  2.0     2.0    0.0       0.0       0.0   \n",
       "8    35.0  50.0     26.0   140.0  2.0    21.0    0.0       1.0       0.0   \n",
       "9    49.0  51.0     27.0    63.0  4.0    19.0    0.0       1.0       0.0   \n",
       "\n",
       "   longmon  ...  pager  internet  callwait  confer  ebill  loglong  logtoll  \\\n",
       "0     4.40  ...    1.0       0.0       1.0     1.0    0.0    1.482    3.033   \n",
       "1     9.45  ...    0.0       0.0       0.0     0.0    0.0    2.246    3.240   \n",
       "2     6.30  ...    0.0       0.0       0.0     1.0    0.0    1.841    3.240   \n",
       "3     6.05  ...    1.0       1.0       1.0     1.0    1.0    1.800    3.807   \n",
       "4     7.10  ...    0.0       0.0       1.0     1.0    0.0    1.960    3.091   \n",
       "5    20.70  ...    0.0       0.0       0.0     0.0    0.0    3.030    3.240   \n",
       "6     8.25  ...    0.0       1.0       1.0     1.0    1.0    2.110    3.157   \n",
       "7     2.90  ...    0.0       0.0       0.0     0.0    0.0    1.065    3.240   \n",
       "8     6.50  ...    0.0       0.0       1.0     1.0    0.0    1.872    3.314   \n",
       "9    12.85  ...    0.0       1.0       1.0     0.0    1.0    2.553    3.248   \n",
       "\n",
       "   lninc  custcat  churn  \n",
       "0  4.913      4.0    1.0  \n",
       "1  3.497      1.0    1.0  \n",
       "2  3.401      3.0    0.0  \n",
       "3  4.331      4.0    0.0  \n",
       "4  4.382      3.0    0.0  \n",
       "5  4.787      1.0    0.0  \n",
       "6  3.611      4.0    0.0  \n",
       "7  2.833      1.0    0.0  \n",
       "8  4.942      3.0    0.0  \n",
       "9  4.143      2.0    0.0  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data\n",
    "churn_df = pd.read_csv('ChurnData.csv')\n",
    "churn_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.,  33.,   7., 136.,   5.,   5.,   0.],\n",
       "       [ 33.,  33.,  12.,  33.,   2.,   0.,   0.],\n",
       "       [ 23.,  30.,   9.,  30.,   1.,   2.,   0.],\n",
       "       [ 38.,  35.,   5.,  76.,   2.,  10.,   1.],\n",
       "       [  7.,  35.,  14.,  80.,   2.,  15.,   0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(churn_df[['tenure','age','address','income','ed','employ','equip']])\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.asarray(churn_df['churn'].astype(int))\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.13518441, -0.62595491, -0.4588971 ,  0.4751423 ,  1.6961288 ,\n",
       "        -0.58477841, -0.85972695],\n",
       "       [-0.11604313, -0.62595491,  0.03454064, -0.32886061, -0.6433592 ,\n",
       "        -1.14437497, -0.85972695],\n",
       "       [-0.57928917, -0.85594447, -0.261522  , -0.35227817, -1.42318853,\n",
       "        -0.92053635, -0.85972695],\n",
       "       [ 0.11557989, -0.47262854, -0.65627219,  0.00679109, -0.6433592 ,\n",
       "        -0.02518185,  1.16316   ],\n",
       "       [-1.32048283, -0.47262854,  0.23191574,  0.03801451, -0.6433592 ,\n",
       "         0.53441472, -0.85972695]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing the data\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (160, 7) (160,)\n",
      "Test set: (40, 7) (40,)\n"
     ]
    }
   ],
   "source": [
    "#Segregating data into test/train datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  Y_train.shape)\n",
    "print ('Test set:', X_test.shape,  Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The version of Logistic Regression in Scikit-learn, support regularization. Regularization is a technique used to solve the overfitting problem in machine learning models. C parameter indicates inverse of regularization strength which must be a positive float. Smaller values specify stronger regularization. Now lets fit our model with train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, solver='liblinear')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the classifier model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Training the model\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,Y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting on test set\n",
    "h_theta = LR.predict(X_test)\n",
    "h_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We will try 3 methods:  \n",
    "Jaccard similiarity index  \n",
    "F1 score  \n",
    "Log loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#JACCARD SIMILIARITY INDEX\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score(h_theta,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1e9ab680100>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#F1 score and confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, h_theta)\n",
    "plot_confusion_matrix(LR,X_test,Y_test, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83        33\n",
      "           1       0.40      0.86      0.55         7\n",
      "\n",
      "    accuracy                           0.75        40\n",
      "   macro avg       0.68      0.79      0.69        40\n",
      "weighted avg       0.86      0.75      0.78        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(h_theta,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we see that the f1-score for the above model in 0.75.\n",
    "Our goal should be to maximize this score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.634874008149465"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOG LOSS\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss(h_theta,Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
